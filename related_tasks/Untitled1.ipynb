{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52191bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97685f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(11)\n",
    "b.append(22)\n",
    "c.append(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d4a25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e1f84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 22]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb317f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 33]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca9d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2e7845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1440, 1080)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.zeros((3,1440,1080))\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0e808ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1440, 1080])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64e9a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 112, 112])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.CenterCrop((112,112))\n",
    "])\n",
    "\n",
    "tensor = transformer(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a3f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29211a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Image.open(\"rgb.jpg\").convert(\"RGB\")\n",
    "depth_np = np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fbed9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1440, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4696116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_1 = transforms.Compose([\n",
    "    transforms.Resize((112,112)),\n",
    "#     transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transformer_2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((112,112))\n",
    "])\n",
    "\n",
    "t1 = torch.from_numpy(depth_np)\n",
    "t2 = torch.from_numpy(depth_np)\n",
    "\n",
    "# new_1 = transformer_1(d)\n",
    "# new_2 = transformer_2(d)\n",
    "new_1 = transformer_1(t1)\n",
    "# new_2 = transformer_2(t2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4ff20217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(new_1))\n",
    "new_1 = np.array(new_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "12655a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "print(new_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03912dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((112,112)),\n",
    "#     transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e625e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "\n",
    "if a <= b:\n",
    "    print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20efbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrkim",
   "language": "python",
   "name": "yrkim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

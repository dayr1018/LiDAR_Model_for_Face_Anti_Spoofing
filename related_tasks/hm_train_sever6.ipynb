{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a809c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113 True 2\n",
      "server : server6 , copy_before_model : False\n"
     ]
    }
   ],
   "source": [
    "from curses import init_color\n",
    "import os\n",
    "import os.path as osp\n",
    "import copy\n",
    "import sys\n",
    "import time \n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.AutoEncoder import AutoEncoder_RGB, AutoEncoder_Depth\n",
    "from models.AutoEncoder import AutoEncoder_Intergrated_Basic, AutoEncoder_Intergrated_Proposed\n",
    "from models.Network import Face_Detection_Model\n",
    "from dataloader.dataloader import load_dataset, load_test_dataset\n",
    "from utility import draw_train_and_test_loss, draw_train_and_test_loss1, draw_accuracy_and_f1_during_training, draw_accuracy_and_f1_during_training1\n",
    "\n",
    "print(torch.__version__,torch.cuda.is_available(),torch.cuda.device_count())\n",
    "copy_before_model = False\n",
    "server = 'server6'\n",
    "print(f'server : {server} , copy_before_model : {copy_before_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d7810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8231a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2**32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "def booltype(str):\n",
    "    if isinstance(str, bool):\n",
    "        return str\n",
    "    if str.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif str.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentError(\"Boolean value expected\")\n",
    "\n",
    "# def model_save(model, epoch, optimizer, train_loss, val_loss, train_f1, valid_f1, path) :\n",
    "#     torch.save({\n",
    "#                 'model_state_dict': model.state_dict(),\n",
    "#                 'epoch': epoch,\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'train_loss': train_loss,\n",
    "#                 'val_loss' : val_loss,\n",
    "#                 'train_f1' : train_f1,\n",
    "#                 'val_f1' : valid_f1\n",
    "#                 }, path)\n",
    "#     print('Model Save ! > ', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5cbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args option\n",
    "parser = argparse.ArgumentParser(description='face anto-spoofing')\n",
    "parser.add_argument('--batchsize', default=4, type=int, help='batch size')\n",
    "parser.add_argument('--workers', default=4, type=int, help='number of workers, 4')\n",
    "parser.add_argument('--epochs', default=100, type=int, help='train epochs')        \n",
    "parser.add_argument('--trainratio', default=1.0, type=float, help='ratio to divide train dataset')                               \n",
    "parser.add_argument('--lr', default=1e-3, type=float, help='learning rate(default: 0.001)')\n",
    "parser.add_argument('--skf', default=0, type=int, help='stratified k-fold')\n",
    "parser.add_argument('--attacktype', default='prm', type=str, help='Kinds of Presentation Attacks: r, p, m, prm')\n",
    "parser.add_argument('--dataset', default=12, type=int, help='dataset type: 12 or 15')\n",
    "parser.add_argument('--model', default='', type=str, help='rgb, rgbd, rgbp, rgbdp')   \n",
    "parser.add_argument('--inputchannel', default=3, type=int, help='inputchannel')\n",
    "parser.add_argument('--crop', default=False, type=booltype, help='use crop (default: False)')\n",
    "parser.add_argument('--ae-path', default='', type=str, help='Pretrained AutoEncoder path')\n",
    "parser.add_argument('--save-path', default='./hm_save_file', type=str, help='train logs path')\n",
    "parser.add_argument('--model-path', default='', type=str, help='model parameter path')\n",
    "# parser.add_argument('--init-path', default='', type=str, help='model init parameter path')\n",
    "# parser.add_argument('--message', default='', type=str, help='parameter file name')                     \n",
    "parser.add_argument('--seed', default=1, type=int, help='Seed for random number generator')\n",
    "parser.add_argument('--cuda', default=0, type=int, help='gpu number')                                         \n",
    "parser.add_argument('--device', default='', type=str, help='device when cuda is available')                       \n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac19373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f56b05edd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_seed(random_seed):\n",
    "    \"\"\"\n",
    "    fix seed to control any randomness from a code \n",
    "    (enable stability of the experiments' results.)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "#     torch.use_deterministic_algorithms(True)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "#     os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    \n",
    "fix_seed(args.seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26737e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bba03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2a6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(args, train_loader, test_loader, outdoor_loader, dark_loader):\n",
    "    \n",
    "    # Model 생성 및 아키텍쳐 출력   \n",
    "    model = Face_Detection_Model(args.inputchannel).to(args.device)    \n",
    "    # original = model.parameters()\n",
    "    \n",
    "    # ckpt = torch.load(args.init_path)\n",
    "    # model.load_state_dict(ckpt['model_state_dict'])\n",
    "    # init = model.parameters()\n",
    "    \n",
    "    # a, b = [], []\n",
    "    # for param in original:\n",
    "    #     a.append(param)\n",
    "    # for param in init:\n",
    "    #     b.append(param)\n",
    "    # for i in range(len(a)):\n",
    "    #     compare = torch.eq(a[i], b[i])\n",
    "    #     # print(compare)\n",
    "    #     # print(torch.any(compare))  \n",
    "    #     print(f\"{a[i]} {b[i]}\")\n",
    "    \n",
    "    # Loss, 옵티마이저, 스케줄러 생성 \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "        \n",
    "    # Train \n",
    "    train_performs = {'ACC':[],'F1':[]}\n",
    "    test_performs = {'ACC':[],'F1':[], 'Info':[]}\n",
    "    outdoor_performs = {'ACC':[],'F1':[], 'Info':[]}\n",
    "    dark_performs = {'ACC':[],'F1':[], 'Info':[]}\n",
    "\n",
    "    # Variables \n",
    "    total_train_loss = []\n",
    "    total_test_loss = []\n",
    "    total_outdoor_loss = []\n",
    "    total_dark_loss = []\n",
    "    \n",
    "    best_test_f1 = 0\n",
    "    best_test_epoch = 0   \n",
    "    best_test_accu = 0 \n",
    "    \n",
    "    epochs = args.epochs + 1\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # model_save(model, 0, optimizer, 0, 0, 0 , 0, osp.join(args.model_path, f\"init_parameter.pth\")) \n",
    "    \n",
    "    fisrt_init_path = './hm_save_file/server1_beforetrain.pth'\n",
    "    if server == 'server1' :\n",
    "        if copy_before_model :\n",
    "            global before_model\n",
    "            before_model = copy.deepcopy(model)\n",
    "            \n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        },fisrt_init_path)\n",
    "    elif server == 'server6' :\n",
    "        global check_model\n",
    "            \n",
    "        checkpoint = torch.load(fisrt_init_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        check_model = copy.deepcopy(model)\n",
    "    \n",
    "    \n",
    "    indoor_check = {'train_loss':[],'test_loss':[],'train_f1':[],'test_f1':[],'train_acc':[],'test_acc':[]}\n",
    "    outdoor_check  = {'test_loss':[],'test_f1':[],'test_acc':[]}\n",
    "    dark_check = {'test_loss':[],'test_f1':[],'test_acc':[]}\n",
    "\n",
    "    for epoch in range(1, epochs) :\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_probs, train_labels = [],[]\n",
    "        train_bar = tqdm(enumerate(train_loader))\n",
    "        for step, data in train_bar :  \n",
    "            rgb, cloud, depth, label = data\n",
    "            rgb = rgb.float().to(args.device)\n",
    "            cloud = cloud.float().to(args.device)\n",
    "            depth = depth.float().to(args.device)\n",
    "            label = label.float().to(args.device)\n",
    "\n",
    "            features = rgb\n",
    "            if args.model == \"rgbd\":\n",
    "                features = torch.cat([rgb, depth], dim=1)\n",
    "            elif args.model == \"rgbp\":\n",
    "                features = torch.cat([rgb, cloud], dim=1)\n",
    "            elif args.model == \"rgbdp\":\n",
    "                features = torch.cat([rgb, depth, cloud], dim=1)  \n",
    "     \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(features)\n",
    "            \n",
    "            logits = logits[:,0]  # logtit (4.2) 텐서이던데 첫째는 batch 이겠고. 근데 왜 0번째 값만 쓸까?\n",
    "            loss = loss_fn(logits, label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            probs = sigmoid(logits)\n",
    "            train_loss.append(loss.item())\n",
    "            train_probs += probs.cpu().detach().tolist()\n",
    "            train_labels += label.cpu().detach().tolist()\n",
    "            \n",
    "            train_bar.set_description(\"[Train] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(train_loader),\n",
    "                                                        round(loss.item(),5),round(np.array(train_loss).mean(),10)\n",
    "                                                                ))\n",
    "        \n",
    "        train_loss_mean = round(np.array(train_loss).mean(), 10)        \n",
    "        \n",
    "        # scheduler.step()\n",
    "        print(\"[Train] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(train_loader),\n",
    "                                                        round(loss.item(),5),train_loss_mean))    \n",
    "        total_train_loss.append(train_loss_mean)\n",
    "        train_acc = accuracy_score(np.array(train_labels), np.round(train_probs))\n",
    "        train_f1 = f1_score(np.array(train_labels), np.round(train_probs), average='macro')\n",
    "        print(f'Train Accuracy : {train_acc:.4f}')\n",
    "        print(f'Train F1-score : {train_f1:.4f}')\n",
    "        train_performs['ACC'].append(train_acc)\n",
    "        train_performs['F1'].append(train_f1)\n",
    "        print(f'  > Counter(train_labels) : {Counter(train_labels)}')\n",
    "        print(f'  > Counter(train_preds) : {Counter(np.round(train_probs))}')\n",
    "        cf = confusion_matrix(np.array(train_labels), np.round(train_probs))\n",
    "        cf = pd.DataFrame(cf)\n",
    "        cf.columns = ['Predicted:0','Predicted:1']\n",
    "        cf.index = ['Label:0','Label:1']    \n",
    "        print(' --- [Train] Confustion_Matrix & Classification_Report --- ')\n",
    "        \n",
    "        # display(cf)\n",
    "        print(cf.to_string())\n",
    "        report = classification_report(np.array(train_labels), np.round(train_probs))\n",
    "        print(report)\n",
    "        \n",
    "        indoor_check['train_loss'].append(np.array(train_loss).mean())\n",
    "        indoor_check['train_f1'].append(train_f1)\n",
    "        indoor_check['train_acc'].append(train_acc)\n",
    "            \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        test_probs, test_labels = [],[]\n",
    "        \n",
    "        # Indoor \n",
    "        test_bar = tqdm(enumerate(test_loader))\n",
    "        for step, data in test_bar :  \n",
    "            rgb, cloud, depth, label = data\n",
    "            rgb = rgb.float().to(args.device)\n",
    "            cloud = cloud.float().to(args.device)\n",
    "            depth = depth.float().to(args.device)\n",
    "            label = label.float().to(args.device)\n",
    "            \n",
    "            features = rgb\n",
    "            if args.model == \"rgbd\":\n",
    "                features = torch.cat([rgb, depth], dim=1)\n",
    "            elif args.model == \"rgbp\":\n",
    "                features = torch.cat([rgb, cloud], dim=1)\n",
    "            elif args.model == \"rgbdp\":\n",
    "                features = torch.cat([rgb, depth, cloud], dim=1)  \n",
    "\n",
    "            logits,_ = model(features)\n",
    "            logits = logits[:,0]\n",
    "            loss = loss_fn(logits, label.float())\n",
    "            \n",
    "            probs = sigmoid(logits)\n",
    "            test_loss.append(loss.item())\n",
    "            test_probs += probs.cpu().detach().tolist()\n",
    "            test_labels += label.cpu().detach().tolist()        \n",
    "            test_bar.set_description(\"[Test] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(test_loader),\n",
    "                                                        round(loss.item(),5),round(np.array(test_loss).mean(),5)\n",
    "                                                                ))\n",
    "            \n",
    "        indoor_check['test_loss'].append(np.array(test_loss).mean())\n",
    "        indoor_check['test_f1'].append(f1_score(np.array(test_labels), np.round(test_probs), average='macro'))\n",
    "        indoor_check['test_acc'].append(accuracy_score(np.array(test_labels), np.round(test_probs)))\n",
    "            \n",
    "        outdoor_loss = []\n",
    "        outdoor_probs, outdoor_labels = [], []\n",
    "            \n",
    "        outdoor_bar = tqdm(enumerate(outdoor_loader))\n",
    "        for step, data in outdoor_bar :  \n",
    "            rgb, cloud, depth, label = data\n",
    "            rgb = rgb.float().to(args.device)\n",
    "            cloud = cloud.float().to(args.device)\n",
    "            depth = depth.float().to(args.device)\n",
    "            label = label.float().to(args.device)\n",
    "            \n",
    "            features = rgb\n",
    "            if args.model == \"rgbd\":\n",
    "                features = torch.cat([rgb, depth], dim=1)\n",
    "            elif args.model == \"rgbp\":\n",
    "                features = torch.cat([rgb, cloud], dim=1)\n",
    "            elif args.model == \"rgbdp\":\n",
    "                features = torch.cat([rgb, depth, cloud], dim=1)  \n",
    "\n",
    "            logits,_ = model(features)\n",
    "            logits = logits[:,0]\n",
    "            loss = loss_fn(logits, label.float())\n",
    "            \n",
    "            probs = sigmoid(logits)\n",
    "            outdoor_loss.append(loss.item())\n",
    "            outdoor_probs += probs.cpu().detach().tolist()\n",
    "            outdoor_labels += label.cpu().detach().tolist()        \n",
    "            outdoor_bar.set_description(\"[Test] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(test_loader),\n",
    "                                                        round(loss.item(),5),round(np.array(outdoor_loss).mean(),5)\n",
    "                                                                ))\n",
    "        \n",
    "        outdoor_check['test_loss'].append(np.array(outdoor_loss).mean())\n",
    "        outdoor_check['test_f1'].append(f1_score(np.array(outdoor_labels), np.round(outdoor_probs), average='macro'))\n",
    "        outdoor_check['test_acc'].append(accuracy_score(np.array(outdoor_labels), np.round(outdoor_probs)))\n",
    "          \n",
    "        dark_loss = []\n",
    "        dark_probs, dark_labels = [], []  \n",
    "          \n",
    "        dark_bar = tqdm(enumerate(dark_loader))\n",
    "        for step, data in dark_bar :  \n",
    "            rgb, cloud, depth, label = data\n",
    "            rgb = rgb.float().to(args.device)\n",
    "            cloud = cloud.float().to(args.device)\n",
    "            depth = depth.float().to(args.device)\n",
    "            label = label.float().to(args.device)\n",
    "            \n",
    "            features = rgb\n",
    "            if args.model == \"rgbd\":\n",
    "                features = torch.cat([rgb, depth], dim=1)\n",
    "            elif args.model == \"rgbp\":\n",
    "                features = torch.cat([rgb, cloud], dim=1)\n",
    "            elif args.model == \"rgbdp\":\n",
    "                features = torch.cat([rgb, depth, cloud], dim=1)  \n",
    "\n",
    "            logits,_ = model(features)\n",
    "            logits = logits[:,0]\n",
    "            loss = loss_fn(logits, label.float())\n",
    "            \n",
    "            probs = sigmoid(logits)\n",
    "            dark_loss.append(loss.item())\n",
    "            dark_probs += probs.cpu().detach().tolist()\n",
    "            dark_labels += label.cpu().detach().tolist()        \n",
    "            dark_bar.set_description(\"[Test] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(test_loader),\n",
    "                                                        round(loss.item(),5),round(np.array(dark_loss).mean(),5)\n",
    "                                                                ))\n",
    "                \n",
    "        dark_check['test_loss'].append(np.array(dark_loss).mean())\n",
    "        dark_check['test_f1'].append(f1_score(np.array(dark_labels), np.round(dark_probs), average='macro'))\n",
    "        dark_check['test_acc'].append(accuracy_score(np.array(dark_labels), np.round(dark_probs)))          \n",
    "            \n",
    "        print(\"[Test] Epoch[{}/{}][{}/{}] Loss:{} Loss(mean):{}\".format(epoch,epochs-1,step+1,len(test_loader),\n",
    "                                                        round(loss.item(),5),round(np.array(test_loss).mean(),5)))\n",
    "        test_loss_mean = round(np.array(test_loss).mean(),10)\n",
    "        outdoor_loss_mean = round(np.array(outdoor_loss).mean(),10)\n",
    "        dark_loss_mean = round(np.array(dark_loss).mean(),10)\n",
    "        total_test_loss.append(test_loss_mean)\n",
    "        total_outdoor_loss.append(outdoor_loss_mean)\n",
    "        total_dark_loss.append(dark_loss_mean)\n",
    "        test_acc = accuracy_score(np.array(test_labels), np.round(test_probs))\n",
    "        test_f1 = f1_score(np.array(test_labels), np.round(test_probs), average='macro')\n",
    "        outdoor_acc = accuracy_score(np.array(outdoor_labels), np.round(outdoor_probs))\n",
    "        outdoor_f1 = f1_score(np.array(outdoor_labels), np.round(outdoor_probs), average='macro')\n",
    "        dark_acc = accuracy_score(np.array(dark_labels), np.round(dark_probs))\n",
    "        dark_f1 = f1_score(np.array(dark_labels), np.round(dark_probs), average='macro')        \n",
    "        \n",
    "        print(f'Test Accuracy : {test_acc:.4f}')\n",
    "        print(f'Test F1-score : {test_f1:.4f}')\n",
    "        test_performs['ACC'].append(test_acc)\n",
    "        test_performs['F1'].append(test_f1)\n",
    "        outdoor_performs['ACC'].append(outdoor_acc)\n",
    "        outdoor_performs['F1'].append(outdoor_f1)\n",
    "        dark_performs['ACC'].append(dark_acc)\n",
    "        dark_performs['F1'].append(dark_f1)\n",
    "        # logger.Print(f'  > Counter(test_labels) : {Counter(test_labels)}')\n",
    "        # logger.Print(f'  > Counter(test_probs) : {Counter(np.round(test_probs))}')\n",
    "        test_cf = confusion_matrix(np.array(test_labels), np.round(test_probs))\n",
    "        test_cf = pd.DataFrame(test_cf)\n",
    "        test_cf.columns = ['Predicted:0','Predicted:1']\n",
    "        test_cf.index = ['Label:0','Label:1']    \n",
    "        print(' --- [Test] Confustion_Matrix & Classification_Report --- ')\n",
    "        # display(test_cf)\n",
    "        print(test_cf.to_string())\n",
    "        test_performs['Info'].append(test_cf.to_string())\n",
    "        test_report = classification_report(np.array(test_labels), np.round(test_probs))\n",
    "        print(test_report)   \n",
    "        \n",
    "        outdoor_acc = accuracy_score(np.array(dark_labels), np.round(dark_probs))\n",
    "        outdoor_F1 = f1_score(np.array(dark_labels), np.round(dark_probs), average='macro')\n",
    "        outdoor_l = np.array(dark_loss).mean()\n",
    "                \n",
    "        dark_acc = accuracy_score(np.array(dark_labels), np.round(dark_probs))\n",
    "        dark_F1 = f1_score(np.array(dark_labels), np.round(dark_probs), average='macro')\n",
    "        dark_l = np.array(dark_loss).mean()\n",
    "        \n",
    "        # 모두 다 저장 \n",
    "        print(' @@ New Save Situation !! @@ ')  \n",
    "        print(f' @@ New Current Epoch : {epoch}')    \n",
    "        print(f' ')\n",
    "        print(f' @@ New Train Accuracy : {train_acc:.4f}')\n",
    "        print(f' @@ New Train F1-Score : {train_f1:.4f}')\n",
    "        print(f' ')\n",
    "        print(f' @@ New Indoor Accuracy : {test_acc:.4f}')\n",
    "        print(f' @@ New Indoor F1-Score : {test_f1:.4f}')\n",
    "        print(f' ')\n",
    "        print(f' @@ New Outdoor Accuracy : {outdoor_acc:.4f}')\n",
    "        print(f' @@ New Outdoor F1-Score : {outdoor_F1:.4f}')\n",
    "        print(f' ')\n",
    "        print(f' @@ New Dark Accuracy : {dark_acc:.4f}')\n",
    "        print(f' @@ New Dark F1-Score : {dark_F1:.4f}')\n",
    "        print(f' ')\n",
    "        print(f' @@ New Train Loss : {train_loss_mean:}') \n",
    "        print(f' @@ New Indoor Loss : {np.array(test_loss).mean():}') \n",
    "        print(f' @@ New Outdoor Loss : {outdoor_l}')\n",
    "        print(f' @@ New Dark Loss : {dark_l}')\n",
    "        print(f' ')\n",
    "        print(f'Saving Model ..... ')\n",
    "                    \n",
    "#         model_save(model,epoch,optimizer,np.array(train_loss).mean(),np.array(test_loss).mean(),\n",
    "#                 train_f1,test_f1,\n",
    "#                 osp.join(args.model_path, f\"epoch_{epoch}_model\"+'.pth'))            \n",
    "                \n",
    "    draw_train_and_test_loss(args, total_train_loss, total_test_loss)\n",
    "    draw_accuracy_and_f1_during_training(args, test_performs[\"ACC\"], test_performs[\"F1\"])\n",
    "    draw_train_and_test_loss1(args, total_train_loss, total_test_loss, total_outdoor_loss, total_dark_loss)\n",
    "    draw_accuracy_and_f1_during_training1(args, train_performs[\"ACC\"], train_performs[\"F1\"], test_performs[\"ACC\"], test_performs[\"F1\"]\n",
    "                                          ,outdoor_performs[\"ACC\"], outdoor_performs[\"F1\"], dark_performs[\"ACC\"], dark_performs[\"F1\"])\n",
    "    \n",
    "    print(' @@ THE END @@ ')\n",
    "    print(f'  > Train Best Accuracy : {np.array(train_performs[\"ACC\"]).max():.4f}')\n",
    "    print(f'  > Train Best F1-Score : {np.array(train_performs[\"F1\"]).max():.4f}')\n",
    "    print(f'  > Test Best Accuracy : {best_test_accu:.4f}')\n",
    "    print(f'  > Test Epoch (Best Accuracy): {best_test_epoch}')  \n",
    "    print(f'  > Test Best F1-Score : {best_test_f1:.4f}')\n",
    "    print(f'  > Test Epoch (Best F1-Score): {best_test_epoch}') \n",
    "    print(f'  > Test Best CF (std: F1)') \n",
    "    print(f'  > {np.array(test_performs[\"Info\"][best_test_epoch-1])}')\n",
    "    print(f'')\n",
    "    \n",
    "    indoor_check_file = f\"{args.save_path}/indoor.pkl\"\n",
    "    outdoor_check_file = f\"{args.save_path}/outdoor.pkl\"\n",
    "    dark_check_file = f\"{args.save_path}/dark.pkl\"\n",
    "    \n",
    "    indoor_max = np.array(indoor_check[\"test_f1\"]).max()\n",
    "    outdoor_max = np.array(outdoor_check[\"test_f1\"]).max()\n",
    "    dark_max = np.array(dark_check[\"test_f1\"]).max()\n",
    "    \n",
    "    indoor_epochs = []\n",
    "    for idx, value in enumerate(indoor_check.values()):\n",
    "        if value == indoor_max:\n",
    "            indoor_epochs.append(idx+1)\n",
    "    outdoor_epochs = []\n",
    "    for idx, value in enumerate(outdoor_check.values()):\n",
    "        if value == outdoor_max:\n",
    "            outdoor_epochs.append(idx+1)\n",
    "    dark_epochs = []\n",
    "    for idx, value in enumerate(dark_check.values()):\n",
    "        if value == dark_max:\n",
    "            dark_epochs.append(idx+1)\n",
    "\n",
    "\n",
    "    \n",
    "    with open(indoor_check_file,'wb') as f:\n",
    "        pickle.dump(indoor_check,f)\n",
    "    with open(outdoor_check_file,'wb') as f:\n",
    "        pickle.dump(outdoor_check,f)\n",
    "    with open(dark_check_file,'wb') as f:\n",
    "        pickle.dump(dark_check,f)       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce1a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790e8961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(ae_path='', attacktype='p', batchsize=4, crop=False, cuda=0, dataset=12, device='', epochs=100, inputchannel=3, lr=0.001, model='rgbp', model_path='', save_path='./hm_save_file', seed=1, skf=0, trainratio=1.0, workers=4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model = 'rgbp'\n",
    "args.attacktype = 'p'\n",
    "args.epochs = 100 ## 1\n",
    "args.cuda = 0\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e19943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'rgb':\n",
    "    args.inputchannel = 3\n",
    "elif args.model == 'rgbd':\n",
    "    args.inputchannel = 4\n",
    "elif args.model == 'rgbp':\n",
    "    args.inputchannel = 6\n",
    "elif args.model == 'rgbdp':\n",
    "    args.inputchannel = 7\n",
    "else:\n",
    "    print(\"You need to checkout option 'model' [rgb, rgbd, rgbp, rgbpc]\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be465b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "# cuda 관련 코드\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "if use_cuda : \n",
    "    if args.cuda == 0:\n",
    "        args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    elif args.cuda == 1:\n",
    "        args.device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    print('device :', args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912d9c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8c9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4c8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "120\n",
      "480\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_dataset(args)\n",
    "outdoor_testset = load_test_dataset(args, \"2. Outdoor\")\n",
    "indoor_dark_testset = load_test_dataset(args, \"3. Indoor_dark\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batchsize, shuffle=False, \n",
    "                          num_workers=args.workers, pin_memory=True,\n",
    "                          worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batchsize, shuffle=False, \n",
    "                         num_workers=args.workers, pin_memory=True,\n",
    "                         worker_init_fn=seed_worker,generator=g)\n",
    "outdoor_loader = DataLoader(outdoor_testset, batch_size=args.batchsize, shuffle=False, \n",
    "                            num_workers=args.workers, pin_memory=True,\n",
    "                            worker_init_fn=seed_worker,generator=g)\n",
    "dark_loader = DataLoader(indoor_dark_testset, batch_size=args.batchsize, shuffle=False,\n",
    "                         num_workers=args.workers, pin_memory=True,\n",
    "                         worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35ff77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[1/100][90/90] Loss:0.00308 Loss(mean):0.377712222: : 90it [00:12,  7.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[1/100][90/90] Loss:0.00308 Loss(mean):0.377712222\n",
      "Train Accuracy : 0.8667\n",
      "Train F1-score : 0.8666\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 188, 0.0: 172})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          152           28\n",
      "Label:1           20          160\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.84      0.86       180\n",
      "         1.0       0.85      0.89      0.87       180\n",
      "\n",
      "    accuracy                           0.87       360\n",
      "   macro avg       0.87      0.87      0.87       360\n",
      "weighted avg       0.87      0.87      0.87       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[1/100][30/30] Loss:0.22637 Loss(mean):0.23851: : 30it [00:01, 17.70it/s]\n",
      "[Test] Epoch[1/100][120/30] Loss:0.02705 Loss(mean):0.44708: : 120it [00:11, 10.08it/s]\n",
      "[Test] Epoch[1/100][120/30] Loss:3.39183 Loss(mean):1.87055: : 120it [00:10, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[1/100][120/30] Loss:3.39183 Loss(mean):0.23851\n",
      "Test Accuracy : 0.9083\n",
      "Test F1-score : 0.9076\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1           11           49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92        60\n",
      "         1.0       1.00      0.82      0.90        60\n",
      "\n",
      "    accuracy                           0.91       120\n",
      "   macro avg       0.92      0.91      0.91       120\n",
      "weighted avg       0.92      0.91      0.91       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 1\n",
      " \n",
      " @@ New Train Accuracy : 0.8667\n",
      " @@ New Train F1-Score : 0.8666\n",
      " \n",
      " @@ New Indoor Accuracy : 0.9083\n",
      " @@ New Indoor F1-Score : 0.9076\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.6958\n",
      " @@ New Outdoor F1-Score : 0.6648\n",
      " \n",
      " @@ New Dark Accuracy : 0.6958\n",
      " @@ New Dark F1-Score : 0.6648\n",
      " \n",
      " @@ New Train Loss : 0.377712222\n",
      " @@ New Indoor Loss : 0.2385067525089653\n",
      " @@ New Outdoor Loss : 1.8705504765076815\n",
      " @@ New Dark Loss : 1.8705504765076815\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[2/100][90/90] Loss:0.00131 Loss(mean):0.141942114: : 90it [00:08, 10.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[2/100][90/90] Loss:0.00131 Loss(mean):0.141942114\n",
      "Train Accuracy : 0.9583\n",
      "Train F1-score : 0.9583\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({0.0: 181, 1.0: 179})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          173            7\n",
      "Label:1            8          172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       180\n",
      "         1.0       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[2/100][30/30] Loss:0.0016 Loss(mean):0.10651: : 30it [00:03,  8.90it/s] \n",
      "[Test] Epoch[2/100][120/30] Loss:0.00284 Loss(mean):0.31317: : 120it [00:09, 12.74it/s]\n",
      "[Test] Epoch[2/100][120/30] Loss:3.23555 Loss(mean):1.65979: : 120it [00:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[2/100][120/30] Loss:3.23555 Loss(mean):0.10651\n",
      "Test Accuracy : 0.9750\n",
      "Test F1-score : 0.9750\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            3           57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98        60\n",
      "         1.0       1.00      0.95      0.97        60\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.97      0.97       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 2\n",
      " \n",
      " @@ New Train Accuracy : 0.9583\n",
      " @@ New Train F1-Score : 0.9583\n",
      " \n",
      " @@ New Indoor Accuracy : 0.9750\n",
      " @@ New Indoor F1-Score : 0.9750\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.6729\n",
      " @@ New Outdoor F1-Score : 0.6391\n",
      " \n",
      " @@ New Dark Accuracy : 0.6729\n",
      " @@ New Dark F1-Score : 0.6391\n",
      " \n",
      " @@ New Train Loss : 0.141942114\n",
      " @@ New Indoor Loss : 0.10651084488490596\n",
      " @@ New Outdoor Loss : 1.6597939890530446\n",
      " @@ New Dark Loss : 1.6597939890530446\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[3/100][90/90] Loss:0.00153 Loss(mean):0.1266647755: : 90it [00:09,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[3/100][90/90] Loss:0.00153 Loss(mean):0.1266647755\n",
      "Train Accuracy : 0.9667\n",
      "Train F1-score : 0.9667\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 184, 0.0: 176})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          172            8\n",
      "Label:1            4          176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       180\n",
      "         1.0       0.96      0.98      0.97       180\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[3/100][30/30] Loss:0.0131 Loss(mean):0.01065: : 30it [00:03,  9.38it/s] \n",
      "[Test] Epoch[3/100][120/30] Loss:0.40241 Loss(mean):0.31955: : 120it [00:11, 10.63it/s]\n",
      "[Test] Epoch[3/100][120/30] Loss:0.20362 Loss(mean):0.33376: : 120it [00:10, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[3/100][120/30] Loss:0.20362 Loss(mean):0.01065\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 3\n",
      " \n",
      " @@ New Train Accuracy : 0.9667\n",
      " @@ New Train F1-Score : 0.9667\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.8688\n",
      " @@ New Outdoor F1-Score : 0.8677\n",
      " \n",
      " @@ New Dark Accuracy : 0.8688\n",
      " @@ New Dark F1-Score : 0.8677\n",
      " \n",
      " @@ New Train Loss : 0.1266647755\n",
      " @@ New Indoor Loss : 0.010648181444654863\n",
      " @@ New Outdoor Loss : 0.3337570902192965\n",
      " @@ New Dark Loss : 0.3337570902192965\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[4/100][90/90] Loss:0.00034 Loss(mean):0.00971644: : 90it [00:08, 10.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[4/100][90/90] Loss:0.00034 Loss(mean):0.00971644\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[4/100][30/30] Loss:0.00108 Loss(mean):0.00124: : 30it [00:03,  8.55it/s]\n",
      "[Test] Epoch[4/100][120/30] Loss:0.25075 Loss(mean):0.43671: : 120it [00:11, 10.82it/s]\n",
      "[Test] Epoch[4/100][120/30] Loss:0.16624 Loss(mean):0.4959: : 120it [00:11, 10.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[4/100][120/30] Loss:0.16624 Loss(mean):0.00124\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 4\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7812\n",
      " @@ New Outdoor F1-Score : 0.7769\n",
      " \n",
      " @@ New Dark Accuracy : 0.7812\n",
      " @@ New Dark F1-Score : 0.7769\n",
      " \n",
      " @@ New Train Loss : 0.00971644\n",
      " @@ New Indoor Loss : 0.0012374451088059382\n",
      " @@ New Outdoor Loss : 0.49590342106142393\n",
      " @@ New Dark Loss : 0.49590342106142393\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[5/100][90/90] Loss:0.00012 Loss(mean):0.0028564797: : 90it [00:08, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[5/100][90/90] Loss:0.00012 Loss(mean):0.0028564797\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[5/100][30/30] Loss:0.00022 Loss(mean):0.00028: : 30it [00:02, 11.20it/s]\n",
      "[Test] Epoch[5/100][120/30] Loss:0.2252 Loss(mean):0.53082: : 120it [00:11, 10.04it/s] \n",
      "[Test] Epoch[5/100][120/30] Loss:0.11029 Loss(mean):0.4898: : 120it [00:10, 11.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[5/100][120/30] Loss:0.11029 Loss(mean):0.00028\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 5\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7979\n",
      " @@ New Outdoor F1-Score : 0.7960\n",
      " \n",
      " @@ New Dark Accuracy : 0.7979\n",
      " @@ New Dark F1-Score : 0.7960\n",
      " \n",
      " @@ New Train Loss : 0.0028564797\n",
      " @@ New Indoor Loss : 0.0002810446310225719\n",
      " @@ New Outdoor Loss : 0.489804874038479\n",
      " @@ New Dark Loss : 0.489804874038479\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[6/100][90/90] Loss:7e-05 Loss(mean):0.0016888645: : 90it [00:08, 10.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[6/100][90/90] Loss:7e-05 Loss(mean):0.0016888645\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[6/100][30/30] Loss:0.00014 Loss(mean):0.00017: : 30it [00:02, 10.40it/s]\n",
      "[Test] Epoch[6/100][120/30] Loss:0.2068 Loss(mean):0.57003: : 120it [00:09, 12.24it/s] \n",
      "[Test] Epoch[6/100][120/30] Loss:0.14164 Loss(mean):0.54072: : 120it [00:11, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[6/100][120/30] Loss:0.14164 Loss(mean):0.00017\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 6\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7750\n",
      " @@ New Outdoor F1-Score : 0.7709\n",
      " \n",
      " @@ New Dark Accuracy : 0.7750\n",
      " @@ New Dark F1-Score : 0.7709\n",
      " \n",
      " @@ New Train Loss : 0.0016888645\n",
      " @@ New Indoor Loss : 0.0001710487458088513\n",
      " @@ New Outdoor Loss : 0.5407180565894426\n",
      " @@ New Dark Loss : 0.5407180565894426\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[7/100][90/90] Loss:5e-05 Loss(mean):0.0011774968: : 90it [00:09,  9.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[7/100][90/90] Loss:5e-05 Loss(mean):0.0011774968\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[7/100][30/30] Loss:9e-05 Loss(mean):0.00011: : 30it [00:03,  9.89it/s]  \n",
      "[Test] Epoch[7/100][120/30] Loss:0.18481 Loss(mean):0.60119: : 120it [00:13,  9.11it/s]\n",
      "[Test] Epoch[7/100][120/30] Loss:0.16079 Loss(mean):0.57797: : 120it [00:08, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[7/100][120/30] Loss:0.16079 Loss(mean):0.00011\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 7\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7583\n",
      " @@ New Outdoor F1-Score : 0.7518\n",
      " \n",
      " @@ New Dark Accuracy : 0.7583\n",
      " @@ New Dark F1-Score : 0.7518\n",
      " \n",
      " @@ New Train Loss : 0.0011774968\n",
      " @@ New Indoor Loss : 0.0001147772238861459\n",
      " @@ New Outdoor Loss : 0.577974548486721\n",
      " @@ New Dark Loss : 0.577974548486721\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[8/100][90/90] Loss:3e-05 Loss(mean):0.0008823545: : 90it [00:06, 14.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[8/100][90/90] Loss:3e-05 Loss(mean):0.0008823545\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[8/100][30/30] Loss:6e-05 Loss(mean):8e-05: : 30it [00:04,  6.76it/s]    \n",
      "[Test] Epoch[8/100][120/30] Loss:0.16495 Loss(mean):0.62723: : 120it [00:13,  9.16it/s]\n",
      "[Test] Epoch[8/100][120/30] Loss:0.17623 Loss(mean):0.61022: : 120it [00:11, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[8/100][120/30] Loss:0.17623 Loss(mean):8e-05\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 8\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7625\n",
      " @@ New Outdoor F1-Score : 0.7546\n",
      " \n",
      " @@ New Dark Accuracy : 0.7625\n",
      " @@ New Dark F1-Score : 0.7546\n",
      " \n",
      " @@ New Train Loss : 0.0008823545\n",
      " @@ New Indoor Loss : 8.232989415167443e-05\n",
      " @@ New Outdoor Loss : 0.6102166426542681\n",
      " @@ New Dark Loss : 0.6102166426542681\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[9/100][90/90] Loss:2e-05 Loss(mean):0.0006905689: : 90it [00:07, 12.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[9/100][90/90] Loss:2e-05 Loss(mean):0.0006905689\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Epoch[9/100][30/30] Loss:5e-05 Loss(mean):6e-05: : 30it [00:01, 22.50it/s]   \n",
      "[Test] Epoch[9/100][120/30] Loss:0.14571 Loss(mean):0.64905: : 120it [00:04, 24.50it/s]\n",
      "[Test] Epoch[9/100][120/30] Loss:0.18903 Loss(mean):0.63859: : 120it [00:09, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Epoch[9/100][120/30] Loss:0.18903 Loss(mean):6e-05\n",
      "Test Accuracy : 1.0000\n",
      "Test F1-score : 1.0000\n",
      " --- [Test] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0           60            0\n",
      "Label:1            0           60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      " @@ New Save Situation !! @@ \n",
      " @@ New Current Epoch : 9\n",
      " \n",
      " @@ New Train Accuracy : 1.0000\n",
      " @@ New Train F1-Score : 1.0000\n",
      " \n",
      " @@ New Indoor Accuracy : 1.0000\n",
      " @@ New Indoor F1-Score : 1.0000\n",
      " \n",
      " @@ New Outdoor Accuracy : 0.7562\n",
      " @@ New Outdoor F1-Score : 0.7467\n",
      " \n",
      " @@ New Dark Accuracy : 0.7562\n",
      " @@ New Dark F1-Score : 0.7467\n",
      " \n",
      " @@ New Train Loss : 0.0006905689\n",
      " @@ New Indoor Loss : 6.207663379124521e-05\n",
      " @@ New Outdoor Loss : 0.6385933533660136\n",
      " @@ New Dark Loss : 0.6385933533660136\n",
      " \n",
      "Saving Model ..... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch[10/100][90/90] Loss:2e-05 Loss(mean):0.0005574293: : 90it [00:08, 10.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch[10/100][90/90] Loss:2e-05 Loss(mean):0.0005574293\n",
      "Train Accuracy : 1.0000\n",
      "Train F1-score : 1.0000\n",
      "  > Counter(train_labels) : Counter({1.0: 180, 0.0: 180})\n",
      "  > Counter(train_preds) : Counter({1.0: 180, 0.0: 180})\n",
      " --- [Train] Confustion_Matrix & Classification_Report --- \n",
      "         Predicted:0  Predicted:1\n",
      "Label:0          180            0\n",
      "Label:1            0          180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       180\n",
      "         1.0       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00       360\n",
      "   macro avg       1.00      1.00      1.00       360\n",
      "weighted avg       1.00      1.00      1.00       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "print('Train Start !')\n",
    "train(args, train_loader, test_loader, outdoor_loader, dark_loader)\n",
    "\n",
    "train_time = str(timedelta(seconds=time.time()-train_start)).split(\".\")\n",
    "print(f\"Train Execution Time: {train_time}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686dc209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06baa133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947b527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.eval()\n",
    "print(check_model.bn1.running_mean)\n",
    "print(check_model.bn1.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f518d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd164c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d26d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in check_model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in check_model.fc.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a601b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader :\n",
    "    break\n",
    "print(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "i[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e784aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d51afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[0][0].permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03703e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644363b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0][0].permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058335fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0][3].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fff9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de9b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985849c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4880ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm1",
   "language": "python",
   "name": "hm1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

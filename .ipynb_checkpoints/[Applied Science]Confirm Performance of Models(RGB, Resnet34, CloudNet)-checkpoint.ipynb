{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073a616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.functional as func\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import argparse\n",
    "\n",
    "from models.Network import Face_Detection_Model, rgbdp_v1_twostep_model, rgbdp_v3_twostep_model\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from re import S\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T \n",
    "# from dataloader.dataloader import load_dataset, load_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "rgb_model = Face_Detection_Model(3).to(device)\n",
    "basic_model = rgbdp_v3_twostep_model(device=device)\n",
    "cloudnet = rgbdp_v1_twostep_model(device=device)\n",
    "\n",
    "rgb = torch.load(\"/mnt/nas4/yrkim/liveness_lidar_project/GC_project/bc_output/checkpoint/0825_total_rgb/epoch_832_model.pth\")\n",
    "basic = torch.load(\"/mnt/nas4/yrkim/liveness_lidar_project/GC_project/bc_output/checkpoint/0828_total_rgbdp_v3/epoch_832_model.pth\")\n",
    "cloud = torch.load(\"/mnt/nas4/yrkim/liveness_lidar_project/GC_project/bc_output/checkpoint/0828_total_rgbdp_v1/epoch_832_model.pth\")\n",
    "\n",
    "rgb_model.load_state_dict(rgb['model_state_dict'])\n",
    "basic_model.load_state_dict(basic['model_state_dict'])\n",
    "cloudnet.load_state_dict(cloud['model_state_dict'])\n",
    "\n",
    "simoid = nn.Sigmoid()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(1)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1183ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class aa():\n",
    "#     def __init__(self):\n",
    "#         self.attacktype=\"rpm\"\n",
    " \n",
    "# args = aa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_Data(Dataset):\n",
    "\n",
    "    def __init__(self, data_paths, crop=False):\n",
    "        self.data_paths = data_paths\n",
    "        self.crop = crop\n",
    "        \n",
    "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "        self.transforms = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            normalize\n",
    "        ])   \n",
    "        self.transforms2 = T.Compose([\n",
    "            T.ToTensor()\n",
    "        ])               \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        rgb_path = self.data_paths[index][0]\n",
    "        cloud_path = self.data_paths[index][1]\n",
    "        depth_path = self.data_paths[index][2]   \n",
    "             \n",
    "        # crop setting\n",
    "        crop_width = 90\n",
    "        crop_height = 150\n",
    "        mid_x, mid_y = 90, 90\n",
    "        offset_x, offset_y = crop_width//2, crop_height//2\n",
    "        \n",
    "        # RGB open and crop \n",
    "        rgb_data = cv2.imread(rgb_path)\n",
    "        rgb_data = cv2.cvtColor(rgb_data, cv2.COLOR_BGR2RGB)\n",
    "        rgb_data = cv2.resize(rgb_data, (180,180), interpolation=cv2.INTER_CUBIC)\n",
    "        if self.crop == True:\n",
    "            rgb_data = rgb_data[mid_y-offset_y:mid_y+offset_y, mid_x-offset_x:mid_x+offset_x]     \n",
    "        if self.transforms is not None :\n",
    "            rgb_data = self.transforms(rgb_data)\n",
    "            \n",
    "        # Depth open \n",
    "        depth_data = cv2.imread(depth_path)\n",
    "        depth_data = cv2.cvtColor(depth_data, cv2.COLOR_BGR2GRAY)\n",
    "        depth_data = cv2.resize(depth_data, (180,180), interpolation=cv2.INTER_CUBIC)        \n",
    "        if self.transforms2 is not None :\n",
    "            depth_data = self.transforms2(depth_data)            \n",
    "            \n",
    "        # Point Cloud(192, 256, 3) open and crop \n",
    "        cloud_data = np.load(cloud_path)\n",
    "        cloud_data = cv2.resize(cloud_data, (180,180), interpolation=cv2.INTER_CUBIC)\n",
    "        cloud_data += 5\n",
    "        if self.crop == True:\n",
    "            cloud_data = cloud_data[mid_y-offset_y:mid_y+offset_y, mid_x-offset_x:mid_x+offset_x]\n",
    "        \n",
    "        # Point Cloud and Depth Scaling\n",
    "        shift_value = 0\n",
    "        xcoor = np.array(cloud_data[:, :, 0] + shift_value)\n",
    "        ycoor = np.array(cloud_data[:, :, 1] + shift_value)\n",
    "        zcoor = np.array(cloud_data[:, :, 2] + shift_value)\n",
    "        # depth = np.array(cloud_data[:, :, 3] + shift_value)\n",
    "\n",
    "        # Stadardivation\n",
    "        # xcoor = (xcoor-xcoor.mean())/xcoor.std()\n",
    "        # ycoor = (ycoor-ycoor.mean())/ycoor.std()\n",
    "        # zcoor = (zcoor-zcoor.mean())/zcoor.std()\n",
    "        # depth = (depth-depth.mean())/depth.std()    \n",
    "        \n",
    "        # Min Max         \n",
    "        xcoor = (xcoor-xcoor.min())/(xcoor.max()-xcoor.min())\n",
    "        ycoor = (ycoor-ycoor.min())/(ycoor.max()-ycoor.min())\n",
    "        zcoor = (zcoor-zcoor.min())/(zcoor.max()-zcoor.min())\n",
    "        # depth = (depth-depth.min())/(depth.max()-depth.min())  \n",
    "        \n",
    "        scaled_cloud_data = np.concatenate([xcoor[np.newaxis,:],ycoor[np.newaxis,:],zcoor[np.newaxis,:]]) \n",
    "        # scaled_depth_data = depth[np.newaxis,:]\n",
    "        \n",
    "        # label - { 0 : real , 1 : mask }\n",
    "        if 'bonafide' in rgb_path :\n",
    "            label = 0\n",
    "        elif 'attack_mask' in rgb_path :\n",
    "            label = 1\n",
    "        elif 'attack_replay' in rgb_path :\n",
    "            label = 1\n",
    "        elif 'attack_paper' in rgb_path :\n",
    "            label = 1\n",
    "        # return rgb_data, scaled_cloud_data, scaled_depth_data, label\n",
    "        return rgb_data, scaled_cloud_data, depth_data, label\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "    \n",
    "    \n",
    "def load_dataset(args): \n",
    "        \n",
    "    ## Input : RGB(3-channel) + Depth(1-channel) + Point_Cloud(3-channel)\n",
    "    data_path = '/mnt/nas3/yrkim/liveness_lidar_project/GC_project/LDFAS/1. Indoor'\n",
    "    npy_path = '/mnt/nas3/yrkim/liveness_lidar_project/GC_project/LDFAS/NPY_Files/1. Indoor'\n",
    "\n",
    "    traindata_count = [i for i in range(1,10)] # 1~9\n",
    "    testdata_count = [i for i in range(10,13)]  # 10~12    \n",
    " \n",
    "    train_img_paths = []\n",
    "    for i in traindata_count :\n",
    "        img_path = osp.join(data_path, str(i), 'bonafide')\n",
    "        files = os.listdir(img_path)\n",
    "        rgbs = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='rgb')]\n",
    "        depths = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='depth')]\n",
    "        random.shuffle(rgbs)\n",
    "        random.shuffle(depths)\n",
    "        \n",
    "        # RGB \n",
    "        bonafide_files = [osp.join(data_path, str(i), 'bonafide', j) for j in rgbs]\n",
    "        paper_files= [osp.join(data_path, str(i), 'attack_paper', j) for j in rgbs]\n",
    "        replay_files= [osp.join(data_path, str(i), 'attack_replay', j) for j in rgbs]\n",
    "        mask_files= [osp.join(data_path, str(i), 'attack_mask', j) for j in rgbs]\n",
    "        \n",
    "        # Depth\n",
    "        bonafide_depths = [osp.join(data_path, str(i), 'bonafide', j) for j in depths]\n",
    "        paper_depths= [osp.join(data_path, str(i), 'attack_paper', j) for j in depths]\n",
    "        replay_depths= [osp.join(data_path, str(i), 'attack_replay', j) for j in depths]\n",
    "        mask_depths= [osp.join(data_path, str(i), 'attack_mask', j) for j in depths]       \n",
    "        \n",
    "        # Point Cloud\n",
    "        bonafide_cloud_files = [osp.join(npy_path, 'real_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in bonafide_files]\n",
    "        paper_cloud_files = [osp.join(npy_path, 'paper_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in paper_files]\n",
    "        replay_cloud_files = [osp.join(npy_path, 'replay_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in replay_files]\n",
    "        mask_cloud_files = [osp.join(npy_path, 'mask_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in mask_files]\n",
    "        \n",
    "        # bonafide\n",
    "        train_img_paths += list(zip(bonafide_files,bonafide_cloud_files,bonafide_depths))[:]\n",
    "        \n",
    "        # PAs\n",
    "        if \"p\" in args:\n",
    "            train_img_paths += list(zip(paper_files,paper_cloud_files,paper_depths))[:]\n",
    "        if \"r\" in args:\n",
    "            train_img_paths += list(zip(replay_files,replay_cloud_files,replay_depths))[:]\n",
    "        if \"m\" in args:\n",
    "            train_img_paths += list(zip(mask_files,mask_cloud_files,mask_depths))[:]\n",
    " \n",
    "    test_img_paths = []\n",
    "    for i in testdata_count :\n",
    "        img_path = osp.join(data_path, str(i), 'bonafide')\n",
    "        files = os.listdir(img_path)\n",
    "        rgbs = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='rgb')]\n",
    "        depths = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='depth')]\n",
    "        random.shuffle(rgbs)\n",
    "        random.shuffle(depths)\n",
    "        \n",
    "        # RGB\n",
    "        bonafide_files = [osp.join(data_path, str(i), 'bonafide', j) for j in rgbs]\n",
    "        paper_files= [osp.join(data_path, str(i), 'attack_paper', j) for j in rgbs]\n",
    "        replay_files= [osp.join(data_path, str(i), 'attack_replay', j) for j in rgbs]\n",
    "        mask_files= [osp.join(data_path, str(i), 'attack_mask', j) for j in rgbs]\n",
    "        \n",
    "        # Depth\n",
    "        bonafide_depths = [osp.join(data_path, str(i), 'bonafide', j) for j in depths]\n",
    "        paper_depths= [osp.join(data_path, str(i), 'attack_paper', j) for j in depths]\n",
    "        replay_depths= [osp.join(data_path, str(i), 'attack_replay', j) for j in depths]\n",
    "        mask_depths= [osp.join(data_path, str(i), 'attack_mask', j) for j in depths]        \n",
    "        \n",
    "        # Point Cloud\n",
    "        bonafide_cloud_files = [osp.join(npy_path, 'real_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in bonafide_files]\n",
    "        paper_cloud_files = [osp.join(npy_path, 'paper_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in paper_files]\n",
    "        replay_cloud_files = [osp.join(npy_path, 'replay_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in replay_files]\n",
    "        mask_cloud_files = [osp.join(npy_path, 'mask_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in mask_files]\n",
    "        \n",
    "        # bonafide\n",
    "        test_img_paths += list(zip(bonafide_files,bonafide_cloud_files,bonafide_depths))[:]\n",
    "        \n",
    "        # PAs\n",
    "        if \"p\" in args:\n",
    "            test_img_paths += list(zip(paper_files,paper_cloud_files,paper_depths))[:]\n",
    "        if \"r\" in args:\n",
    "            test_img_paths += list(zip(replay_files,replay_cloud_files,replay_depths))[:]\n",
    "        if \"m\" in args:\n",
    "            test_img_paths += list(zip(mask_files,mask_cloud_files,mask_depths))[:]\n",
    "        \n",
    "    random.shuffle(train_img_paths)\n",
    "    random.shuffle(test_img_paths)\n",
    "\n",
    "    print(len(train_img_paths))\n",
    "    print(len(test_img_paths))\n",
    "    \n",
    "#     train_dataset=Face_Data(train_img_paths, False)\n",
    "#     test_dataset=Face_Data(test_img_paths, False) \n",
    "\n",
    "    return train_img_paths, test_img_paths\n",
    "\n",
    "\n",
    "def load_test_dataset(args, dir_name): \n",
    "        \n",
    "    ## Input : RGB(3-channel) + Depth(1-channel) + Point_Cloud(3-channel)\n",
    "    LDFAS_path = '/mnt/nas3/yrkim/liveness_lidar_project/GC_project/LDFAS/'\n",
    "    data_path = osp.join(LDFAS_path, dir_name)\n",
    "    npy_path = osp.join(LDFAS_path, \"NPY_Files\", dir_name)\n",
    "         \n",
    "    testdata_count = [i for i in range(1,13)]  # 1~12    \n",
    "    test_img_paths = []\n",
    "    for i in testdata_count :\n",
    "        img_path = osp.join(data_path, str(i), 'bonafide')\n",
    "        files = os.listdir(img_path)\n",
    "        rgbs = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='rgb')]\n",
    "        depths = [j for j in files if (j.split('.')[-1]=='jpg') and (j.split('_')[0]=='depth')]\n",
    "        random.shuffle(rgbs)\n",
    "        random.shuffle(depths)\n",
    "        \n",
    "        # RGB\n",
    "        bonafide_files = [osp.join(data_path, str(i), 'bonafide', j) for j in rgbs]\n",
    "        paper_files= [osp.join(data_path, str(i), 'attack_paper', j) for j in rgbs]\n",
    "        replay_files= [osp.join(data_path, str(i), 'attack_replay', j) for j in rgbs]\n",
    "        mask_files= [osp.join(data_path, str(i), 'attack_mask', j) for j in rgbs]\n",
    "        \n",
    "        # Depth\n",
    "        bonafide_depths = [osp.join(data_path, str(i), 'bonafide', j) for j in depths]\n",
    "        paper_depths= [osp.join(data_path, str(i), 'attack_paper', j) for j in depths]\n",
    "        replay_depths= [osp.join(data_path, str(i), 'attack_replay', j) for j in depths]\n",
    "        mask_depths= [osp.join(data_path, str(i), 'attack_mask', j) for j in depths]        \n",
    "               \n",
    "        # Point Cloud\n",
    "        bonafide_cloud_files = [osp.join(npy_path, 'real_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in bonafide_files]\n",
    "        paper_cloud_files = [osp.join(npy_path, 'paper_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in paper_files]\n",
    "        replay_cloud_files = [osp.join(npy_path, 'replay_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in replay_files]\n",
    "        mask_cloud_files = [osp.join(npy_path, 'mask_cloud_data',j.split('/')[-3], \n",
    "                                (('pc_'+j.split('/')[-1].split('_')[-1]).split('.')[0]+'.npy')) for j in mask_files]\n",
    "        \n",
    "        # bonafide\n",
    "        test_img_paths += list(zip(bonafide_files,bonafide_cloud_files,bonafide_depths))[:]\n",
    "        \n",
    "        # PAs\n",
    "        if \"p\" in args:\n",
    "            test_img_paths += list(zip(paper_files,paper_cloud_files,paper_depths))[:]\n",
    "        if \"r\" in args:\n",
    "            test_img_paths += list(zip(replay_files,replay_cloud_files,replay_depths))[:]\n",
    "        if \"m\" in args:\n",
    "            test_img_paths += list(zip(mask_files,mask_cloud_files,mask_depths))[:]\n",
    "     \n",
    "    random.shuffle(test_img_paths)\n",
    "    print(len(test_img_paths))\n",
    "    \n",
    "#     test_dataset=Face_Data(test_img_paths, False) \n",
    "\n",
    "    return test_img_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb01d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indoor_test_paths = load_dataset(args)\n",
    "# outdoor_testset = load_test_dataset(args, \"2. Outdoor\")\n",
    "# darkdoor_testset = load_test_dataset(args, \"3. Indoor_dark\")\n",
    "\n",
    "_, indoor_dataloader = DataLoader(indoor_testset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n",
    "# outdoor_dataloader = DataLoader(outdoor_testset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n",
    "# darkdoor_dataloader = DataLoader(darkdoor_testset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=seed_worker, generator=g)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e08283",
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_testset=Face_Data(indoor_test_paths, False)\n",
    "\n",
    "\n",
    "# train_dataset=Face_Data(train_img_paths, False)\n",
    "# test_dataset=Face_Data(test_img_paths, False)\n",
    "\n",
    "# test_dataset=Face_Data(test_img_paths, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe02603",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "//\n",
    "//\n",
    "for data in indoor_dataloader:\n",
    "    rgb, pt, depth, label = data\n",
    "    \n",
    "    rgb_logit = rgb_model(rgb)\n",
    "    pred = sigmoid(rgb_logit)\n",
    "    //\n",
    "    //\n",
    "    \n",
    "    rgb_prob = loss_fn(pred, label)\n",
    "    //\n",
    "    //\n",
    "    \n",
    "    y_true.append()\n",
    "    y_pred.append()\n",
    "\n",
    "# Confusion Matrix\n",
    "# BPCER\n",
    "# APCER\n",
    "# ACER\n",
    "# FAR\n",
    "# FRR\n",
    "# HEER \n",
    "# AOC \n",
    "# TPR, FPR \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df65bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b602d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bb9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acdecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094de3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8663050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05b13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d9f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd50447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53703aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873be667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d17400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0233f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452ca9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd28c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d71ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba9c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26bf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df01eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrkim",
   "language": "python",
   "name": "yrkim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
